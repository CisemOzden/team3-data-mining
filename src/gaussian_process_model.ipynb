{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save environment parameters, so those won't be saved to report file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_variables = dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model related constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "INPUT_TRAINING_FILE = \"../data/original/training_dataset.csv\"\n",
    "INPUT_EVALUATION_FILE = \"../data/original/evaluation_dataset.csv\"\n",
    "\n",
    "# Output parameters\n",
    "METHOD_NAME = \"gaussian_process\"\n",
    "TIMESTAMP = time.strftime(\"%d_%m_%Y-%H_%M_%S\")\n",
    "OUTPUT_MODEL = f\"../data/models/{METHOD_NAME}_model_{TIMESTAMP}.pkl\"\n",
    "OUTPUT_RESULTS = f\"../data/results/{METHOD_NAME}_model_{TIMESTAMP}.txt\"\n",
    "\n",
    "# Hyper parameter alternatives\n",
    "HYPER_PARAMETER_K_FEATURES = list(range(5, 30, 5))\n",
    "HYPER_PARAMETER_SCORE_FUNC = [chi2]\n",
    "# HYPER_PARAMETER_N_COMPONENTS = [3, 5, 7, 10, 15]\n",
    "HYPER_PARAMETER_N_RESTARTS_OPTIMIZER = list(range(0, 2, 1))\n",
    "\n",
    "# Hyper parameter optimization parameters\n",
    "# HYPER_PARAMETER_OPTIMIZATION_SCORING = \"balanced_accuracy\"\n",
    "HYPER_PARAMETER_OPTIMIZATION_BETA = 2\n",
    "HYPER_PARAMETER_OPTIMIZATION_CV = 5\n",
    "\n",
    "# Other constants\n",
    "LABELS = [\"Operational\", \"Bankrupt\"]\n",
    "RANDOM_SEED = 42\n",
    "VERBOSITY = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "These dataset should contain \"Bankrupt?\" label and features that should be considered during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv(INPUT_TRAINING_FILE, engine=\"python\", delimiter=\",\")\n",
    "training_features = training_dataset.loc[:, training_dataset.columns != \"Bankrupt?\"]\n",
    "training_targets = training_dataset[\"Bankrupt?\"]\n",
    "\n",
    "evaluation_dataset = pd.read_csv(INPUT_EVALUATION_FILE, engine=\"python\", delimiter=\",\")\n",
    "evaluation_features = evaluation_dataset.loc[:, evaluation_dataset.columns != \"Bankrupt?\"]\n",
    "evaluation_targets = evaluation_dataset[\"Bankrupt?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor preprocessing\n",
    "Remove constant Net Income Flag and  Liability-Assets Flag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = training_features.drop(columns=[\" Net Income Flag\"])\n",
    "evaluation_features = evaluation_features.drop(columns=[\" Net Income Flag\"])\n",
    "training_features = training_features.drop(columns=[\" Liability-Assets Flag\"])\n",
    "evaluation_features = evaluation_features.drop(columns=[\" Liability-Assets Flag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create internal pipeline\n",
    "classifier = GaussianProcessClassifier()\n",
    "standard_scaler =  StandardScaler()\n",
    "min_max_scaler =  MinMaxScaler()\n",
    "feature_selection = SelectKBest()\n",
    "# pca = PCA(random_state=RANDOM_SEED)\n",
    "smote = SMOTE(sampling_strategy=\"minority\", random_state=RANDOM_SEED)\n",
    "pipeline = Pipeline(steps=[(\"standard_scaler\", standard_scaler),(\"min_max_scaler\", min_max_scaler),\n",
    "    (\"selection\", feature_selection), (\"smote\", smote), (\"classification\", classifier)])\n",
    "\n",
    "# Specify the tunable hyper parameters\n",
    "parameters = {\n",
    "    \"selection__k\": HYPER_PARAMETER_K_FEATURES,\n",
    "    \"selection__score_func\": HYPER_PARAMETER_SCORE_FUNC,\n",
    "    \"classification__n_restarts_optimizer\": HYPER_PARAMETER_N_RESTARTS_OPTIMIZER\n",
    "}\n",
    "\n",
    "# Define KFold parameters\n",
    "cv = StratifiedKFold(n_splits=HYPER_PARAMETER_OPTIMIZATION_CV, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define custom fbeta scorer function that put emphasis on recall\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=HYPER_PARAMETER_OPTIMIZATION_BETA)\n",
    "\n",
    "estimator = GridSearchCV(pipeline, parameters, verbose=VERBOSITY,\n",
    "    scoring=make_scorer(custom_scorer), cv=cv, n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function chi2 at 0x7fae66718040>;, score=0.153 total time= 3.5min\n",
      "[CV 2/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function chi2 at 0x7fc41afd6040>;, score=0.158 total time= 3.5min\n",
      "[CV 3/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function chi2 at 0x7f55df0f8040>;, score=0.209 total time= 3.9min\n",
      "[CV 4/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function chi2 at 0x7fae66718040>;, score=0.234 total time= 3.6min\n",
      "[CV 5/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function chi2 at 0x7fc41afd6040>;, score=0.404 total time= 3.7min\n",
      "[CV 1/5] END classification__n_restarts_optimizer=0, selection__k=5, selection__score_func=<function f_classif at 0x7f55df1a6ee0>;, score=0.453 total time= 4.3min\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(training_features, training_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_to_string(cm):\n",
    "    return f\"True operational={cm[0][0]}, True bankrupt={cm[1][1]}, False operational={cm[0][1]}, False bankrupt={cm[1][0]}\"\n",
    "\n",
    "# Use all training data to calculate confusion matrix for training data\n",
    "training_estimates = estimator.predict(training_features)\n",
    "training_accuracy = balanced_accuracy_score(training_targets, training_estimates)\n",
    "training_confusion_matrix = confusion_matrix(training_targets, training_estimates)\n",
    "training_confusion_matrix = confusion_matrix_to_string(training_confusion_matrix)\n",
    "training_classification_report = classification_report(training_targets, training_estimates, output_dict=True, target_names=LABELS)\n",
    "training_f_beta_score = fbeta_score(training_targets, training_estimates, beta=HYPER_PARAMETER_OPTIMIZATION_BETA)\n",
    "\n",
    "# Use model to estimate manually labeled evaluation Tweets\n",
    "evaluation_estimates = estimator.predict(evaluation_features)\n",
    "evaluation_accuracy = balanced_accuracy_score(evaluation_targets, evaluation_estimates)\n",
    "evaluation_confusion_matrix = confusion_matrix(evaluation_targets, evaluation_estimates)\n",
    "evaluation_confusion_matrix = confusion_matrix_to_string(evaluation_confusion_matrix)\n",
    "evaluation_classification_report = classification_report(evaluation_targets, evaluation_estimates, output_dict=True, target_names=LABELS)\n",
    "evaluation_f_beta_score = fbeta_score(evaluation_targets, evaluation_estimates, beta=HYPER_PARAMETER_OPTIMIZATION_BETA)\n",
    "\n",
    "# Store best parameters\n",
    "best_parameters = estimator.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_MODEL, \"wb\") as handle:\n",
    "    pickle.dump(estimator, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metadata and calculated statistics\n",
    "This is done by saving every textual and numerical variable to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_variables = dir()\n",
    "\n",
    "results_string = \"\"\n",
    "\n",
    "for variable in current_variables:\n",
    "    # Skip environment variables and their container variable\n",
    "    # Ignore also underscore variables\n",
    "    if variable in environment_variables or variable == \"environment_variables\" or variable.startswith(\"_\"):\n",
    "        continue\n",
    "\n",
    "    # Get variables value\n",
    "    variable_value = globals()[variable]\n",
    "\n",
    "    # If variable is numerical or string, append it to results\n",
    "    if type(variable_value) is str or type(variable_value) is int or \\\n",
    "        type(variable_value) is float or type(variable_value) is list or \\\n",
    "        type(variable_value) is numpy.float64 or type(variable_value) is dict:\n",
    "        results_string += f\"{variable}: {variable_value}\\n\"\n",
    "\n",
    "# Print results to screen\n",
    "print(results_string)\n",
    "\n",
    "# Save results to file\n",
    "with open(OUTPUT_RESULTS, \"w\") as file:\n",
    "    file.write(results_string)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df7a9a5c37ddd52c7652a98db41541d6c37368917739ba33de99dadb21ef70fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
